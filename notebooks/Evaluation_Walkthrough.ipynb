{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Data Started.\n",
      "Error : b'From https://github.com/CSSEGISandData/COVID-19\\n   d07a81e2..6d759cea  master     -> origin/master\\n   a7eb1798..1fb5004f  web-data   -> origin/web-data\\n'\n",
      "out : b'Updating d07a81e2..6d759cea\\nFast-forward\\n .../csse_covid_19_daily_reports/09-03-2020.csv     | 3955 ++++++++++++\\n .../csse_covid_19_daily_reports_us/09-03-2020.csv  |   59 +\\n .../time_series_covid19_confirmed_US.csv           | 6682 ++++++++++----------\\n .../time_series_covid19_confirmed_global.csv       |  534 +-\\n .../time_series_covid19_deaths_US.csv              | 6682 ++++++++++----------\\n .../time_series_covid19_deaths_global.csv          |  534 +-\\n .../time_series_covid19_recovered_global.csv       |  508 +-\\n 7 files changed, 11484 insertions(+), 7470 deletions(-)\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/09-03-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/09-03-2020.csv\\n'\n",
      "Number of regions row: 16\n",
      "Get Data Started.\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/get_data.py\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_johns_hopkins_data():\n",
    "    git_pull = subprocess.Popen( \"git pull\" ,\n",
    "                     cwd = os.path.dirname( '../data/raw/COVID-19/' ),\n",
    "                     shell = True,\n",
    "                     stdout = subprocess.PIPE,\n",
    "                     stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "def get_current_data_germany():\n",
    "    #fetching data of 16 states.\n",
    "    data = requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "    json_object = json.loads(data.content)\n",
    "    full_list = []\n",
    "    for pos, each_dict in enumerate (json_object['features']):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list = pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('../data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print('Number of regions row: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Get Data Started.')\n",
    "    get_johns_hopkins_data()\n",
    "    get_current_data_germany()\n",
    "    print('Get Data Started.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Pipeline Started.\n",
      "Number of rows stored - Relational Model: 60116\n",
      "Number of rows stored - Full Flat Table: 226\n",
      "<Response [200]>\n",
      "Process Pipeline Ended.\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base = pd_raw.rename(columns={'Country/Region':'country', 'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state'] = pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base = pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "    pd_relational_model = pd_data_base.set_index(['state','country']) \\\n",
    "                                        .T                            \\\n",
    "                                        .stack(level=[0,1])           \\\n",
    "                                        .reset_index()                \\\n",
    "                                        .rename(columns={'level_0':'date',\n",
    "                                                            0:'confirmed'}\n",
    "                                                )\n",
    "\n",
    "    pd_relational_model['date'] = pd_relational_model.date.astype('datetime64[ns]')\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_confirmed.csv',sep=';', index = False)\n",
    "    #print(pd_relational_model.head())\n",
    "    print('Number of rows stored - Relational Model: '+str(pd_relational_model.shape[0]))\n",
    "\n",
    "def store_confimed_data_for_sir():\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "    pd_raw = pd_raw.drop(['Lat','Long','Province/State'],axis=1)\n",
    "    pd_raw = pd_raw.rename(columns={'Country/Region':'country'})\n",
    "    pd_flat_table = pd_raw.set_index('country') \\\n",
    "                    .T \\\n",
    "                    .stack(level=[0]) \\\n",
    "                    .reset_index() \\\n",
    "                    .rename(columns={'level_0':'date',\n",
    "                                    0:'confirmed'}\n",
    "                                    )\n",
    "    pd_flat_table['date'] = pd_flat_table.date.astype('datetime64[ns]')\n",
    "    pd_flat_table = pd.pivot_table(pd_flat_table, values='confirmed', index='date', columns='country', aggfunc=np.sum, fill_value=0).reset_index()\n",
    "    pd_flat_table.to_csv('../data/processed/COVID_full_flat_table.csv',sep=';',index = False)\n",
    "    #print(pd_flat_table.tail())\n",
    "    print('Number of rows stored - Full Flat Table: '+str(pd_flat_table.shape[0]))\n",
    "\n",
    "def fetch_globaldata_api():\n",
    "    url_endpoint = 'https://api.smartable.ai/coronavirus/stats/global'\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Cache-Control': 'no-cache',\n",
    "        'Subscription-Key': '97711648a1aa475c93771173df4ad001',\n",
    "    }\n",
    "    response = requests.get(url_endpoint, headers=headers)\n",
    "    print(response)\n",
    "    global_dict = json.loads(response.content)\n",
    "    df = pd.DataFrame() #{'Nation':['A'],'Type':['A'],'Count':[1]}\n",
    "    for each in global_dict['stats']['breakdowns']:\n",
    "        total_active_case = ((int(each['totalConfirmedCases'])+int(each['newlyConfirmedCases'])) - (int(each['totalDeaths'])+int(each['newDeaths'])) - (int(each['totalRecoveredCases'])+int(each['newlyRecoveredCases'])))\n",
    "        dictJSON={'Nation':each['location']['countryOrRegion'],\n",
    "                 'Total_Confirmed_Cases':int(each['totalConfirmedCases'])+int(each['newlyConfirmedCases']),\n",
    "                 'Total_Deaths':int(each['totalDeaths'])+int(each['newDeaths']),\n",
    "                 'Total_Recovered':int(each['totalRecoveredCases'])+int(each['newlyRecoveredCases']),\n",
    "                 'Total_Active_Cases': int(total_active_case) if total_active_case > 0 else 0 }\n",
    "        df = df.append(dictJSON, ignore_index=True)\n",
    "    df.to_csv('../data/processed/COVID_GlobalDataView.csv',sep=';', index = False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Process Pipeline Started.')\n",
    "    store_relational_JH_data()\n",
    "    store_confimed_data_for_sir()\n",
    "    fetch_globaldata_api()\n",
    "    print('Process Pipeline Ended.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Building Started.\n",
      "       index       date state country  confirmed  confirmed_DR  \\\n",
      "58846  58846 2020-08-30    no   Italy   268218.0    189.979827   \n",
      "59113  59113 2020-08-31    no   Italy   269214.0    227.102922   \n",
      "59378  59378 2020-09-01    no   Italy   270189.0    273.167935   \n",
      "59645  59645 2020-09-02    no   Italy   271515.0    234.946545   \n",
      "59911  59911 2020-09-03    no   Italy   272912.0    199.440813   \n",
      "\n",
      "       confirmed_filtered  confirmed_filtered_DR  \n",
      "58846            267976.6             206.519798  \n",
      "59113            269197.8             217.048167  \n",
      "59378            270409.6             221.286204  \n",
      "59645            271578.5             227.156131  \n",
      "59911            272747.4             232.336812  \n",
      "Feature Building Ended.\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/features/build_features.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from datetime import datetime\n",
    "from scipy import signal\n",
    "\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    '''uses linear regression to approximate the slope'''\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1,1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "\n",
    "    reg.fit(X,y)\n",
    "    intercept = reg.intercept_\n",
    "    slope = reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "def savgol_filter(df_input, column ='confirmed', window = 5):\n",
    "    '''savgol filter. to ensure data structre is kept'''\n",
    "    degree = 1\n",
    "    df_result = df_input\n",
    "    filter_in = df_input[column].fillna(0)\n",
    "\n",
    "    result = signal.savgol_filter(np.array(filter_in),\n",
    "                                 window,\n",
    "                                 degree)\n",
    "    df_result[column+'_filtered'] = result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input, col='confirmed'):\n",
    "    '''df_input -> data frame'''\n",
    "    days_back = 3\n",
    "    result = df_input[col].rolling(\n",
    "                                    window = days_back,\n",
    "                                    min_periods = days_back,\n",
    "                                    ).apply(get_doubling_time_via_regression, raw=False)\n",
    "    return result\n",
    "\n",
    "def calc_filtered_data(df_input, filter_on='confirmed'):\n",
    "    '''\n",
    "        Calculate savgol filter and return merged data frame\n",
    "    '''\n",
    "    must_contain = set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), 'Error in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    pd_filtered_result = df_input[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter).reset_index()\n",
    "    #print(pd_filtered_result.head())\n",
    "    df_output = pd.merge(df_input,pd_filtered_result[['index',filter_on+'_filtered']], on=['index'], how='left')\n",
    "\n",
    "    return df_output\n",
    "\n",
    "def calc_doubling_rate(df_input, filter_on = 'confirmed'):\n",
    "    '''\n",
    "        Calcualte approximated doubling rate and return merged data frame\n",
    "    '''\n",
    "    must_contain = set(['state','country',filter_on])\n",
    "    #print(must_contain)\n",
    "    #print(df_input.columns)\n",
    "    assert must_contain.issubset(set(df_input.columns)), 'Error in calc_doubling_rate not all columns in data frame'\n",
    "\n",
    "    pd_DR_result = df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "    #print(df_input.head())\n",
    "\n",
    "    pd_DR_result = pd_DR_result.rename(columns={filter_on:filter_on+'_DR','level_2':'index'})\n",
    "    #if filter_on == 'confirmed':\n",
    "        #df_input = df_input.reset_index()\n",
    "    #print(df_input.head())\n",
    "    df_output = pd.merge(df_input,pd_DR_result[['index',filter_on+'_DR']], on=['index'],how='left')\n",
    "\n",
    "    return df_output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Feature Building Started.')\n",
    "    #test_data = np.array([2,4,6])\n",
    "    #result = get_doubling_time_via_regression(test_data)\n",
    "    #print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_JH_data = pd.read_csv('../data/processed/COVID_relational_confirmed.csv', sep=';', parse_dates=[0])\n",
    "    # sorting is required - becasue we are assuming sliding window approch; so we are going top to down from first to last sample step by step\n",
    "    pd_JH_data = pd_JH_data.sort_values('date',ascending=True).reset_index(drop = True).copy()\n",
    "    #print(pd_JH_data.columns)\n",
    "    # Index reset is requried as we dropped the index above while sorting. Otherwise index will be messed up and will get out of order results.\n",
    "    pd_JH_data = pd_JH_data.reset_index()\n",
    "    # 1. Calcualte the doubling rate for the non filtered data.\n",
    "    pd_result_large = calc_doubling_rate(pd_JH_data)\n",
    "    # 2. Calcualte the filtered data\n",
    "    pd_result_large = calc_filtered_data(pd_result_large)\n",
    "    #print(pd_result_large.columns)\n",
    "    # 3. Calcualte the doublinf rate for the filtered data.\n",
    "    pd_result_large = calc_doubling_rate(pd_result_large,'confirmed_filtered')\n",
    "    # Mask the data to NaN which has lower than 100 doubling rate. Result in good visualization\n",
    "    mask=pd_result_large['confirmed']>100\n",
    "    pd_result_large['confirmed_filtered_DR']=pd_result_large['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_large.to_csv('../data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_large[pd_result_large['country']=='Italy'].tail())\n",
    "    print('Feature Building Ended.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SIR Model calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIR Modelling Started.\n",
      "Number of rows stored - : 226\n",
      "SIR Modelling Ended.\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/models/sir_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "import warnings\n",
    "\n",
    "'''\n",
    "    Default paramter initializations\n",
    "'''\n",
    "N0 = 5000000\n",
    "I0 = 20   #Infected population\n",
    "S0 = N0 - I0    #Suspected population\n",
    "R0 = 0          #Recovered population\n",
    "beta = 0.4      #Rate of infection\n",
    "gamma = 0.1     #Rate of recovery\n",
    "t = 0\n",
    "\n",
    "def Handle_SIR_Modelling(ydata):\n",
    "    global t\n",
    "    t = np.arange(len(ydata))\n",
    "\n",
    "    global I0\n",
    "    I0 = ydata[0]   #Infected population\n",
    "    popt, pcov = optimize.curve_fit(fit_odeint, t, ydata, maxfev=10000)\n",
    "    fitted = fit_odeint(t, *popt)\n",
    "    return t, ydata, fitted\n",
    "\n",
    "def SIR_model_fit(SIR, time, beta, gamma):\n",
    "    '''\n",
    "    Simple SIR model implementation.\n",
    "    S: Suspected population\n",
    "    I: Infected population\n",
    "    R: Recovered population\n",
    "    beta: rate of infection\n",
    "    gamma: rate of recovery\n",
    "    time: for integral as define in odeint function of scipy.integrate\n",
    "    as per slides: ds+dI+dR = 0 and S+R+I=N (total population)\n",
    "\n",
    "    Make a note tht in this model a recovered person can not get infected again.\n",
    "    '''\n",
    "\n",
    "    S,I,R = SIR\n",
    "    dS_dt = -beta*S*I/N0\n",
    "    dI_dt = beta*S*I/N0 - gamma*I\n",
    "    dR_dt = gamma*I\n",
    "\n",
    "    return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "def fit_odeint(x, beta, gamma):\n",
    "    ''' To call integrate funtion of scipy'''\n",
    "    return integrate.odeint(SIR_model_fit, (S0, I0, R0), t, args=(beta, gamma))[:,1]  #we are only fetching dI\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('SIR Modelling Started.')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    df_analyse = pd.read_csv('../data/processed/COVID_full_flat_table.csv', sep=';')\n",
    "    df_analyse.sort_values('date', ascending=True)\n",
    "    df_analyse = df_analyse.drop(['date'],axis=1)\n",
    "    df_SIR_model = pd.DataFrame()\n",
    "    start_count = 0\n",
    "    total_rows = len(df_analyse.US)\n",
    "    for each_country in df_analyse:\n",
    "        #if each_country == 'Germany':\n",
    "        #print(each_country)\n",
    "        temp_fitted = np.full(total_rows, np.NaN)\n",
    "        df_SIR_model[each_country] = temp_fitted\n",
    "        nonzero_row = (df_analyse[each_country] > start_count).idxmax(1)\n",
    "        ydata = np.array(df_analyse[each_country][nonzero_row:])\n",
    "        t, ydata, fitted = Handle_SIR_Modelling(ydata)\n",
    "        df_SIR_model[each_country].iloc[0:len(fitted)] = fitted\n",
    "    df_SIR_model.to_csv('../data/processed/COVID_SIR_Model_Data.csv',sep=';', index = False)\n",
    "    print('Number of rows stored - : ' + str(df_SIR_model.shape[0]))\n",
    "    print('SIR Modelling Ended.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\College\\Semester_2\\EnterpriseDataScience\\Code\\EDS_Covid\\eda_covid_19\\notebooks\n",
      "Running on http://127.0.0.1:8050/\n",
      "Debugger PIN: 839-280-423\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/visualization/visualize.py\n",
    "# %load ../src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.express as px\n",
    "\n",
    "print(os.getcwd())\n",
    "df_input_large = pd.read_csv('../data/processed/COVID_final_set.csv', sep=';')\n",
    "df_analyse = pd.read_csv('../data/processed/COVID_full_flat_table.csv', sep=';')\n",
    "df_SIR_data = pd.read_csv('../data/processed/COVID_SIR_Model_Data.csv', sep=';')\n",
    "df_Global_data = pd.read_csv('../data/processed/COVID_GlobalDataView.csv', sep=';')\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "df_Global_data_filtered = df_Global_data['Total_Confirmed_Cases'] > 1000\n",
    "df_Global_data_filtered = df_Global_data[df_Global_data_filtered]\n",
    "\n",
    "fig_bar = px.scatter(df_Global_data_filtered, x=\"Total_Active_Cases\", y=\"Total_Deaths\",\n",
    "                 size=\"Total_Confirmed_Cases\", color=\"Total_Recovered\", hover_name=\"Nation\",\n",
    "                 log_x=True, log_y=True, size_max=60, height = 700)\n",
    "fig_bar.update_layout( title = 'Global View of COVID cases (>1k confirmed cases) - size represent Total Confirmed cases; hover to see full details.', title_x=0.5,\n",
    "                xaxis = dict(title='Total Active Cases (Log Scale)'),\n",
    "                yaxis = dict(title='Total Deaths (Log Scale)')\n",
    "                )\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "tabs_styles = {\n",
    "    'height': '44px'\n",
    "}\n",
    "tab_style = {\n",
    "    'borderBottom': '1px solid #d6d6d6',\n",
    "    'padding': '6px',\n",
    "    'fontWeight': 'bold',\n",
    "    'height': '44px'\n",
    "}\n",
    "\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "            # Applied Data science on COVID-19 DataSet\n",
    "            Goal of the project is to learn data science concpet by applying CRISP_DM,\n",
    "            it covers full walkthrough of: automated data gathering, data transformations,\n",
    "            filtering and machine learning to approximating the doubling time, and\n",
    "            {static} deployement of responsive dashboard.\n",
    "\n",
    "            Time-Series : To check and comapre the growth of COVID confirmed cases in different countries.\n",
    "\n",
    "            Global View : To check and comapre countries on different parameter like : confiemd cases, deaths, recovered and active cases.\n",
    "\n",
    "            SIR Model : This view reflects the true growth of infection compare to the predicted growth (using SIR model) in different countries.\n",
    "            '''),\n",
    "\n",
    "\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label='Time-Series Visualization', style=tab_style, children=[\n",
    "\n",
    "            dcc.Markdown('''\n",
    "            ## Multi-Select country for visualization\n",
    "            '''),\n",
    "\n",
    "            dcc.Dropdown(\n",
    "                id = 'country_drop_down',\n",
    "                options = [{'label':name, 'value':name} for name in df_input_large['country'].unique()],\n",
    "                value = ['US', 'Germany', 'India'], # default selected values\n",
    "                multi = True # for allowing multi value selection\n",
    "            ),\n",
    "\n",
    "            dcc.Markdown('''\n",
    "            ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "            '''),\n",
    "\n",
    "            dcc.Dropdown(\n",
    "                id = 'doubling_time',\n",
    "                options = [\n",
    "                    {'label':'Timeline Confirmed', 'value':'confirmed'},\n",
    "                    {'label':'Timeline Confirmed Filtered', 'value':'confirmed_filtered'},\n",
    "                    {'label':'Timeline Doubling Rate', 'value':'confirmed_DR'},\n",
    "                    {'label':'Timeline Doubling Rate Filtered','value':'confirmed_filtered_DR'}\n",
    "                ],\n",
    "                value = 'confirmed', # default selected values\n",
    "                multi = False # Not allowing multi value selection\n",
    "            ),\n",
    "\n",
    "            dcc.Graph(figure=fig, id='main_window_slope'),\n",
    "\n",
    "        ]),\n",
    "\n",
    "        dcc.Tab(label='Global View', style=tab_style, children=[\n",
    "            dcc.Graph(figure=fig_bar, id='gloabl_chart')\n",
    "        ]),\n",
    "\n",
    "        dcc.Tab(label='SIR Model', style=tab_style,  children=[\n",
    "\n",
    "            dcc.Markdown('''\n",
    "            ##  Multi-Select country for visualization.\n",
    "            '''),\n",
    "\n",
    "            dcc.Dropdown(\n",
    "                id = 'country_drop_down_sir',\n",
    "                options = [{'label':name, 'value':name} for name in df_input_large['country'].unique()],\n",
    "                value = ['Germany', 'US'], # default selected values\n",
    "                multi = True # for allowing multi value selection\n",
    "            ),\n",
    "            dcc.Graph(figure=fig, id='sir_chart')\n",
    "        ])\n",
    "\n",
    "    ])\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('sir_chart', 'figure'),\n",
    "    [Input('country_drop_down_sir', 'value')])\n",
    "def update_figure(country_list):\n",
    "    traces = []\n",
    "    if(len(country_list) > 0):\n",
    "        for each in country_list:\n",
    "            nonzero_row = (df_analyse[each] > 0).idxmax(1)\n",
    "            country_data = df_analyse[each][nonzero_row:]\n",
    "            ydata = np.array(country_data)\n",
    "            t = np.arange(len(ydata))\n",
    "            fitted = np.array(df_SIR_data[each])\n",
    "            #t, ydata, fitted = Handle_SIR_Modelling(ydata)\n",
    "\n",
    "            traces.append(dict(\n",
    "                x = t,\n",
    "                y = ydata,\n",
    "                mode = 'markers+lines',\n",
    "                name = each+str(' - Truth'),\n",
    "                opacity = 0.9\n",
    "            ))\n",
    "            traces.append(\n",
    "            dict(\n",
    "                x = t,\n",
    "                y = fitted,\n",
    "                mode = 'markers+lines',\n",
    "                name = each+str(' - Simulation'),\n",
    "                opacity = 0.9\n",
    "            ))\n",
    "    return {\n",
    "        'data': traces,\n",
    "        'layout': dict(\n",
    "            width = 1280,\n",
    "            height = 720,\n",
    "            title = 'Fit of SIR model for: '+', '.join(country_list),\n",
    "            xaxis = {\n",
    "                'title': 'Days', #'Fit of SIR model for '+str(each)+' cases',\n",
    "                'tickangle': -45,\n",
    "                'nticks' : 20,\n",
    "                'tickfont' : dict(size = 14, color = '#7f7f7f')\n",
    "            },\n",
    "            yaxis = {\n",
    "                'title': 'Population Infected',\n",
    "                'type': 'log'\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time','value')])\n",
    "def update_figure(country_list, show_doubling):\n",
    "    ''' Updates figure based on passed coutry list and filter/doubling value'''\n",
    "\n",
    "    if '_DR' in show_doubling:\n",
    "        my_yaxis = {'type':'log',\n",
    "                    'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "                    }\n",
    "    else:\n",
    "        my_yaxis = {'type':'log',\n",
    "                    'title':'Confirmed infected people (source Johns Hopkins CSSE, log-scale)'\n",
    "                    }\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot = df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        # To handle case where we have multiple entry for the same country.\n",
    "        #improvement can be done by removing this call from callback\n",
    "        if show_doubling =='confirmed_filtered_DR':\n",
    "            df_plot = df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot = df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "        traces.append(dict(\n",
    "            x = df_plot.date,\n",
    "            y = df_plot[show_doubling],\n",
    "            mode = 'markers+lines',\n",
    "            name = each,\n",
    "            opacity = 0.9\n",
    "        ))\n",
    "    return {\n",
    "        'data': traces,\n",
    "        'layout': dict(\n",
    "            width = 1280,\n",
    "            height = 720,\n",
    "            xaxis = {\n",
    "                'title': 'Timeline',\n",
    "                'tickangle': -45,\n",
    "                'nticks' : 20,\n",
    "                'tickfont' : dict(size = 14, color = '#7f7f7f')\n",
    "            },\n",
    "            yaxis = my_yaxis\n",
    "        )\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
